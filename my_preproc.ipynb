{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from pyts.preprocessing import InterpolationImputer\n",
    "\n",
    "# just for the sake of this blog post!\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# load the provided data\n",
    "train_features = pd.read_csv('data-processed/dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "train_labels = pd.read_csv('data-processed/dengue_labels_train.csv',\n",
    "                           index_col=[0,1,2])\n",
    "\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# run all preprocessing steps on both cities, then in last step seperate them\n",
    "\n",
    "# load data\n",
    "X_path = 'data-processed/dengue_features_train.csv'\n",
    "y_path = \"data-processed/dengue_labels_train.csv\"\n",
    "\n",
    "# load data and set index to city, year, weekofyear\n",
    "df = pd.read_csv(X_path, index_col=[0, 1, 2])\n",
    "    \n",
    "# select features we want\n",
    "features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "            'reanalysis_dew_point_temp_k', \n",
    "            'station_avg_temp_c', \n",
    "            'station_min_temp_c']#,\n",
    "            #'station_max_temp_c']\n",
    "\n",
    "# select predictors\n",
    "df = df[features]\n",
    "#df = df.drop('week_start_date',axis=1)#[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "df.fillna(method='ffill', inplace=True) # bfill: use next valid observation to fill gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lag to \n",
    "#lag        = 1\n",
    "#var2change = 'station_max_temp_c'\n",
    "\n",
    "#df['humid_lag'] = df[var2change].shift(lag)  # Lagged by 1 time step\n",
    "\n",
    "# remove missing value again because of lag\n",
    "#df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# remove original \n",
    "#df = df.drop(var2change,axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# add predictor to DF to seperate cities\n",
    "y = pd.read_csv(y_path, index_col=[0, 1, 2])\n",
    "df = df.join(y)\n",
    "    \n",
    "# separate san juan and iquitos\n",
    "df_sj = df.loc['sj']\n",
    "df_iq = df.loc['iq']\n",
    "\n",
    "# remove y from X again\n",
    "\n",
    "# San Juan\n",
    "X_sj = df_sj.drop('total_cases',axis=1)\n",
    "y_sj = df_sj['total_cases']\n",
    "\n",
    "# Iquitos\n",
    "X_iq = df_iq.drop('total_cases',axis=1)\n",
    "y_iq = df_iq['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X into prior and future train vs. test sets\n",
    "\n",
    "# San Juan is 936 x 21\n",
    "X_sj_train = X_sj.iloc[1:701]\n",
    "X_sj_test = X_sj.iloc[701:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sj_train = y_sj.iloc[1:701]\n",
    "y_sj_test  = y_sj.iloc[701:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1802.2099802009457\n"
     ]
    }
   ],
   "source": [
    "# my version benchmarking function\n",
    "\n",
    "# San Juan\n",
    "# best alpha =  1e-08\n",
    "# best score =  756.9779411764706\n",
    "\n",
    "# Peru\n",
    "# best alpha =  1e-08\n",
    "# best score =  119.31666666666666\n",
    "\n",
    "def get_score(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    rf_regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "    rf_regressor.fit(X_train, y_train)#\n",
    "\n",
    "    y_pred_train = rf_regressor.predict(X_test)\n",
    "    \n",
    "    return metrics.mean_squared_error(y_test, y_pred_train)\n",
    "\n",
    "# output MSE \n",
    "mse_sj = get_score(X_sj_train, y_sj_train, X_sj_test, y_sj_test)\n",
    "print(mse_sj)\n",
    "\n",
    "# baseline model with 4 features: 1802.2099802009457\n",
    "# baseline model with all features: 1458.708840425532 \n",
    "\n",
    "# experiment on interpolation\n",
    "# after interpolation with 4 feature: 1906.9913617021275 \n",
    "# after interpolation with all features 1762.8954468085103 with all features using ffill\n",
    "# after interpolation with all features 11281.0836463829787 with all features using bfill\n",
    "\n",
    "# experiment on lag, removing original avg_temp\n",
    "# baseline model, 4 features, bfill: 1281.0836463829787\n",
    "# baseline model, 4 features, bfill, lagged by 1 avg, temp: 1623.894638297872\n",
    "# baseline model, 4 features, bfill, lagged by 2 avg, temp: 1454.7012340425533\n",
    "# baseline model, 4 features, bfill, lagged by 3 avg, temp: 1361.6014042553193\n",
    "\n",
    "# experiment on lag, keeping original avg_temp\n",
    "# baseline model, 4 features, bfill: 1281.0836463829787\n",
    "# baseline model, 4 features, bfill, lagged by 1 avg, temp:\n",
    "\n",
    "# experiment on lag, removing original humidity\n",
    "# 1 weeks: 1538.7760425531915\n",
    "# 2 weeks: 1617.551914893617\n",
    "# 3 weeks: 1429.1278297872343\n",
    "\n",
    "# experiment on lag, keeping original humidity\n",
    "# 2 weeks: 1617.551914893617\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of changes to keep\n",
    "\n",
    "### BETTER ###\n",
    "# fill missing values\n",
    "# df.fillna(method='bfill', inplace=True) better than ffill\n",
    "\n",
    "\n",
    "### Worse ###\n",
    "# avg_temp lag of 1-4 all worse"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dsr-b34",
   "language": "python",
   "name": "dsr-b34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
